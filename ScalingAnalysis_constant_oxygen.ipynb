{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Scaling Analysis under constant oxygen environments\n",
    "\n",
    "Using this scaling analysis script allows for applying your single analysis script to a large amount of image sequences organized in the OMERO `project` or `dataset` structures. Therefore, your custom developed analyses can scale to large image volumes without you touching or changing the code. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 1. Setup\n",
    "\n",
    "Define the `omero_id` and `omero_type` of the image data you would like to process. The `omerod_id` is the number you can find in the top right corner when selecting a OMERO `project`, `dataset` or `image` in the `OMERO Web` application. The `omero_type` must be `project` or `dataset` when the OMERO id points to a project or dataset and `image` if it is just a single image! Please note that if you define the wrong `omero_type` you will get an error lateron!\n",
    "\n",
    "Also provide your credentials for the OMERO server!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# OMERO resource that you want to analyze\n",
    "omero_type = \"dataset\" # can be \"image\", \"project\" or \"dataset\"\n",
    "omero_id = 2948 # change the id if you want to apply the analysis to a different omero resource\n",
    "\n",
    "# your omero credentials\n",
    "username = \"<your username>\"\n",
    "password = \"<your password>\"\n",
    "\n",
    "# do not change the lines below\n",
    "assert username != \"<your username>\", \"Please replace '<your username>' with your OMERO username\"\n",
    "assert password != \"<your password>\", \"Please replace '<your password>' with your OMERO username\"\n",
    "\n",
    "import logging\n",
    "\n",
    "if not \"OMERO_SERVER\" in os.environ:\n",
    "    logging.warning(\"No 'OMERO_SERVER' defined. Fallback to default OMERO_SERVER address 'omero'! This can lead to connection faults!\")\n",
    "if not \"OMERO_WEB\" in os.environ:\n",
    "    logging.warning(\"No 'OMERO_WEB' defined. Links to view OMERO data in web viewer might not work!\")\n",
    "\n",
    "credentials = dict(\n",
    "    serverUrl=os.environ.get('OMERO_SERVER', 'omero'),\n",
    "    username=username,\n",
    "    password = password\n",
    ")\n",
    "\n",
    "omero_cred = dict(\n",
    "    host = credentials['serverUrl'],\n",
    "    username = credentials['username'],\n",
    "    passwd = credentials['password']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 1.2 Specify the analysis script\n",
    "\n",
    "Now you have to specify the name of the analysis script you want to apply to the image data. At best copy the script to the same location as this script! Then you only have to specify the name of the script!\n",
    "\n",
    "**Note:** If the analysis script is not located in the same folder you need to specify the path to it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis_script = \"GrowthRate_constant_oxygen.ipynb\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Information about the underlying data\n",
    "\n",
    "We summarize the amount of underlying data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from acia.segm.omero.utils import list_image_ids_in\n",
    "from omero.gateway import BlitzGateway\n",
    "\n",
    "with BlitzGateway(**omero_cred) as conn:\n",
    "    image_ids = list_image_ids_in(omero_id, omero_type, conn)\n",
    "\n",
    "## TODO: give an overview about the data\n",
    "print(image_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Scale the analysis script to all image sequences\n",
    "\n",
    "Now we apply the analysis script to every image sequence individually ðŸš€! You can lean back and enjoy the working computer ðŸ˜Ž ðŸ¥‚\n",
    "\n",
    "**Note:** For heavy analysis scripts or for larget `datasets` or `projects` this process may take a while (from minutes to hours or days). The top-level progress bar will indicate the total progress and give you an indication how long this will take. For large image data volumes we can recommend execution over night ðŸŒ”!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "from acia.analysis import scale\n",
    "\n",
    "# set the base path for all results\n",
    "stem = Path(analysis_script).stem\n",
    "output_path = Path(\"./automated_executions\") / stem / datetime.today().isoformat()\n",
    "\n",
    "print(f\"Results are stored in: {output_path.absolute()}\")\n",
    "\n",
    "# scale your analysis script to many images\n",
    "result = scale(output_path, analysis_script=analysis_script, image_ids=image_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Inspect your analysis results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.parse\n",
    "from IPython.display import Video, Markdown, display\n",
    "\n",
    "base_url = os.environ.get(\"JUPYTERHUB_SERVICE_PREFIX\", None)\n",
    "\n",
    "if base_url is None:\n",
    "    url = f\"file://{output_path.absolute()}\"\n",
    "else:\n",
    "    url = f\"{base_url}lab/tree/{urllib.parse.quote(str(output_path))}\"\n",
    "\n",
    "output = f\"\"\"# Inspect your analyses\n",
    "You can find all the individual analysis scripts here: <a href=\"{url}\">{url}</a>\"\"\"\n",
    "\n",
    "display(Markdown(output))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Generate Summary Statistics\n",
    "\n",
    "In this section you can generate your custom summary statistics that combine the results of all experiment analyses. Just design the analysis script that you scaled above such that it outputs the results into a local files. Here, these results can be loaded, merged together and further processed or visualized!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, \"result_growth-rate.csv\" files are collected from all the analyzed chambers, then mean and std of growth rate are calculated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import os, glob\n",
    "import numpy as np\n",
    "\n",
    "directory = Path(\"./automated_executions\") / stem\n",
    "\n",
    "# Find latest folder\n",
    "latest_folder = Path(max(glob.glob(os.path.join(directory, '*/')), key=os.path.getmtime))\n",
    "print(latest_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = []\n",
    "\n",
    "# if the csv. file exists, take growth rates, otherwise go to the next loop\n",
    "for sub_folder in latest_folder.glob(\"execution*\"):\n",
    "    data_folder =  sub_folder / \"tmp\"\n",
    "    data_files = os.listdir(data_folder)\n",
    "    if \"result_growth-rate.csv\" not in data_files:\n",
    "        print(sub_folder.name, 'was not analyzed')\n",
    "    else:\n",
    "        sub_df = pd.read_csv(data_folder / \"result_growth-rate.csv\", delimiter = ';')\n",
    "        sub_df.loc[len(sub_df)] = {'m': sub_folder.name, 'b': sub_folder.name} # adding a new row (ImageID) to sub_df\n",
    "        dfs.append(sub_df[['m']].T)\n",
    "\n",
    "joint_df = pd.concat(dfs, ignore_index=True)\n",
    "joint_df.columns = ['Cell number', 'Cell area', 'ImageID']\n",
    "print(joint_df)\n",
    "\n",
    "# calculate mean and std of growth rate\n",
    "mean = [np.mean(joint_df['Cell number']), np.mean(joint_df['Cell area'])]\n",
    "std = [np.std(joint_df['Cell number']), np.std(joint_df['Cell area'])]\n",
    "\n",
    "statistics_df = pd.DataFrame({'': ['mean', 'std'],\n",
    "                              'Cell number': [mean[0], std[0]],\n",
    "                              'Cell area': [mean[1], std[1]]})\n",
    "\n",
    "joint_df.to_csv('./ growth-rate_summary.csv', decimal='.', sep=';')\n",
    "statistics_df.to_csv('./ growth-rate_mean-std.csv', decimal='.', sep=';')\n",
    "print(statistics_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Growth rate summary in the box plot\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(5,5))\n",
    "sns.boxplot(data=joint_df)\n",
    "ax.set_ylabel('Growth rate [h$^{-1}$]')\n",
    "ax.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, \"result.csv\" files are collected from all the analyzed chambers, then growth is characterized by population area, mean and std of single cell area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change parameters here\n",
    "dt_image = 10/60   # image acquisition interval (hour)\n",
    "t_start = 1   # analysis start (hour)\n",
    "t_end = 2.5   # analysis end (hour)\n",
    "\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import os, glob\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# if the result.csv file exists, take data\n",
    "growth_df = pd.DataFrame()\n",
    "data_list_t = []\n",
    "pop_area_df = pd.DataFrame()\n",
    "cell_area_mean_df = pd.DataFrame()\n",
    "cell_area_std_df = pd.DataFrame()\n",
    "\n",
    "for sub_folder in latest_folder.glob(\"execution*\"):\n",
    "    data_list = []\n",
    "    data_folder =  sub_folder / \"tmp\"\n",
    "    data_files = os.listdir(data_folder)\n",
    "    \n",
    "    if \"result.csv\" not in data_files:\n",
    "        print(sub_folder.name, 'was not analyzed')\n",
    "        \n",
    "    else:\n",
    "        sub_df = pd.read_csv(data_folder / \"result.csv\", delimiter = ';')\n",
    "        \n",
    "        # collect 'area_sum' & 'area_mean' & 'area_std' from all the analyzed chambers\n",
    "        pop_area_df[sub_folder.name] = sub_df['area_sum']\n",
    "        cell_area_mean_df[sub_folder.name] = sub_df['area_mean'] \n",
    "        cell_area_std_df[sub_folder.name] = sub_df['area_std']\n",
    "\n",
    "\n",
    "# save collected area_sum\n",
    "pop_area_df.insert(0, 'time', sub_df['time'])\n",
    "pop_area_df['mean'] = pop_area_df.mean(axis=1)\n",
    "pop_area_df['std'] = pop_area_df.std(axis=1)\n",
    "pop_area_df.to_csv('./ population-area_summary.csv', decimal='.', sep=';')\n",
    "\n",
    "print('Analysis done!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lastly, \"allcells.csv\" files are collected from all the analyzed chambers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change parameters here\n",
    "dt_image = 10/60   # image acquisition interval (hour)\n",
    "t_start = 1   # analysis start (hour)\n",
    "t_end = 2.5   # analysis end (hour)\n",
    "\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import os, glob\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# if the allcells.csv file exists, take single-cell area data\n",
    "cell_area_df = pd.DataFrame()\n",
    "data = []\n",
    "\n",
    "for sub_folder in latest_folder.glob(\"execution*\"):\n",
    "    data_list = []\n",
    "    data_folder =  sub_folder / \"tmp\"\n",
    "    data_files = os.listdir(data_folder)\n",
    "    \n",
    "    if \"allcells.csv\" not in data_files:\n",
    "        print(sub_folder.name, 'was not analyzed')\n",
    "        \n",
    "    else:\n",
    "        sub_allcells_df = pd.read_csv(data_folder / \"allcells.csv\", delimiter = ';')\n",
    "        timed_sub_allcells_df = sub_allcells_df[(sub_allcells_df['time'] >= t_start) & (sub_allcells_df['time'] <= t_end)]\n",
    "        filtered_allcells_df = sub_allcells_df[sub_allcells_df['time'] == 2]\n",
    "        \n",
    "        cell_area_df[sub_folder.name] = timed_sub_allcells_df['area']\n",
    "        \n",
    "        if not filtered_allcells_df.empty:\n",
    "            for area in filtered_allcells_df['area']:\n",
    "                data.append({'image ID': sub_folder.name, 'area': area})\n",
    "\n",
    "summary_df = pd.DataFrame(data)\n",
    "summary_df.to_csv('./ single-cell_area_2h.csv', decimal='.', sep=';')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "vscode": {
   "interpreter": {
    "hash": "43e720662e2b73f3f858656968524fca68eb44fc0b1d15b9eb878c7d185562f9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
