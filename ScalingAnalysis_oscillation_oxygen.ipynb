{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Scaling Analysis under oscillating oxygen environments\n",
    "\n",
    "Using this scaling analysis script allows for applying your single analysis script to a large amount of image sequences organized in the OMERO `project` or `dataset` structures. Therefore, your custom developed analyses can scale to large image volumes without you touching or changing the code. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 1. Setup\n",
    "\n",
    "Define the `omero_id` and `omero_type` of the image data you would like to process. The `omerod_id` is the number you can find in the top right corner when selecting a OMERO `project`, `dataset` or `image` in the `OMERO Web` application. The `omero_type` must be `project` or `dataset` when the OMERO id points to a project or dataset and `image` if it is just a single image! Please note that if you define the wrong `omero_type` you will get an error lateron ðŸ¤¯!\n",
    "\n",
    "Also provide your credentials for the OMERO server!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# OMERO resource that you want to analyze\n",
    "omero_type = \"dataset\" # can be \"image\", \"project\" or \"dataset\"\n",
    "omero_id = 3446 # change the id if you want to apply the analysis to a different omero resource\n",
    "\n",
    "# your omero credentials\n",
    "username = \"<your username>\"\n",
    "password = \"<your password>\"\n",
    "\n",
    "# do not change the lines below\n",
    "assert username != \"<your username>\", \"Please replace '<your username>' with your OMERO username\"\n",
    "assert password != \"<your password>\", \"Please replace '<your password>' with your OMERO username\"\n",
    "\n",
    "import logging\n",
    "\n",
    "if not \"OMERO_SERVER\" in os.environ:\n",
    "    logging.warning(\"No 'OMERO_SERVER' defined. Fallback to default OMERO_SERVER address 'omero'! This can lead to connection faults!\")\n",
    "if not \"OMERO_WEB\" in os.environ:\n",
    "    logging.warning(\"No 'OMERO_WEB' defined. Links to view OMERO data in web viewer might not work!\")\n",
    "\n",
    "credentials = dict(\n",
    "    serverUrl=os.environ.get('OMERO_SERVER', 'omero'),\n",
    "    username=username,\n",
    "    password = password\n",
    ")\n",
    "\n",
    "omero_cred = dict(\n",
    "    host = credentials['serverUrl'],\n",
    "    username = credentials['username'],\n",
    "    passwd = credentials['password']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 1.2 Specify the analysis script\n",
    "\n",
    "Now you have to specify the name of the analysis script you want to apply to the image data. At best copy the script to the same location as this script! Then you only have to specify the name of the script!\n",
    "\n",
    "**Note:** If the analysis script is not located in the same folder you need to specify the path to it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis_script = \"GrowthRate_oscillation_oxygen.ipynb\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Information about the underlying data\n",
    "\n",
    "We summarize the amount of underlying data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from acia.segm.omero.utils import list_image_ids_in\n",
    "from omero.gateway import BlitzGateway\n",
    "\n",
    "with BlitzGateway(**omero_cred) as conn:\n",
    "    image_ids = list_image_ids_in(omero_id, omero_type, conn)\n",
    "\n",
    "## TODO: give an overview about the data\n",
    "print(image_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Scale the analysis script to all image sequences\n",
    "\n",
    "Now we apply the analysis script to every image sequence individually ðŸš€! You can lean back and enjoy the working computer ðŸ˜Ž ðŸ¥‚\n",
    "\n",
    "**Note:** For heavy analysis scripts or for larget `datasets` or `projects` this process may take a while (from minutes to hours or days). The top-level progress bar will indicate the total progress and give you an indication how long this will take. For large image data volumes we can recommend execution over night ðŸŒ”!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "from acia.analysis import scale\n",
    "\n",
    "# set the base path for all results\n",
    "stem = Path(analysis_script).stem\n",
    "output_path = Path(\"./automated_executions\") / stem / datetime.today().isoformat()\n",
    "\n",
    "print(f\"Results are stored in: {output_path.absolute()}\")\n",
    "\n",
    "# scale your analysis script to many images\n",
    "result = scale(output_path, analysis_script=analysis_script, image_ids=image_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Inspect your analysis results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.parse\n",
    "from IPython.display import Video, Markdown, display\n",
    "\n",
    "base_url = os.environ.get(\"JUPYTERHUB_SERVICE_PREFIX\", None)\n",
    "\n",
    "if base_url is None:\n",
    "    url = f\"file://{output_path.absolute()}\"\n",
    "else:\n",
    "    url = f\"{base_url}lab/tree/{urllib.parse.quote(str(output_path))}\"\n",
    "\n",
    "output = f\"\"\"# Inspect your analyses\n",
    "You can find all the individual analysis scripts here: <a href=\"{url}\">{url}</a>\"\"\"\n",
    "\n",
    "display(Markdown(output))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 5. Generate Summary Statistics\n",
    "\n",
    "In this section you can generate your custom summary statistics that combine the results of all experiment analyses. Just design the analysis script that you scaled above such that it outputs the results into a local files. Here, these results can be loaded, merged together and further processed or visualized!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, \"result_growth-rate.csv\" files are collected from all the analyzed chambers, then mean and std of growth rate are calculated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import os, glob\n",
    "import numpy as np\n",
    "\n",
    "directory = Path(\"./automated_executions\") / stem\n",
    "\n",
    "# Find latest folder\n",
    "latest_folder = Path(max(glob.glob(os.path.join(directory, '*/')), key=os.path.getmtime))\n",
    "print(latest_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = []\n",
    "\n",
    "# if the csv. file exists, take growth rates, otherwise go to the next loop\n",
    "for sub_folder in latest_folder.glob(\"execution*\"):\n",
    "    data_folder =  sub_folder / \"tmp\"\n",
    "    data_files = os.listdir(data_folder)\n",
    "    if \"result_growth-rate.csv\" not in data_files:\n",
    "        print(sub_folder.name, 'was not analyzed')\n",
    "    else:\n",
    "        sub_df = pd.read_csv(data_folder / \"result_growth-rate.csv\", delimiter = ';')\n",
    "        sub_df.loc[len(sub_df)] = {'m': sub_folder.name, 'b': sub_folder.name} # adding a new row (ImageID) to sub_df\n",
    "        dfs.append(sub_df[['m']].T)\n",
    "\n",
    "joint_df = pd.concat(dfs, ignore_index=True)\n",
    "joint_df.columns = ['Cell number', 'Cell area', 'ImageID']\n",
    "print(joint_df)\n",
    "\n",
    "# calculate mean and std of growth rate\n",
    "mean = [np.mean(joint_df['Cell number']), np.mean(joint_df['Cell area'])]\n",
    "std = [np.std(joint_df['Cell number']), np.std(joint_df['Cell area'])]\n",
    "\n",
    "statistics_df = pd.DataFrame({'': ['mean', 'std'],\n",
    "                              'Cell number': [mean[0], std[0]],\n",
    "                              'Cell area': [mean[1], std[1]]})\n",
    "\n",
    "joint_df.to_csv('./ growth-rate_summary.csv', decimal='.', sep=';')\n",
    "statistics_df.to_csv('./ growth-rate_mean-std.csv', decimal='.', sep=';')\n",
    "print(statistics_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Growth rate summary in the box plot\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(5,5))\n",
    "sns.boxplot(data=joint_df)\n",
    "ax.set_ylabel('Growth rate [h$^{-1}$]')\n",
    "ax.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, \"result.csv\" files are collected from all the analyzed chambers, then growth is characterized by calculating instantaneous growth rate ($Âµ_{\\Delta t}$), etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change parameters here\n",
    "dt_image = 1/360   # image acquisition interval (hour)\n",
    "dt_switch = 30/60   # oxygen switch interval (hour)\n",
    "t_start = 1   # analysis start (hour)\n",
    "t_end = 3   # analysis end (hour)\n",
    "\n",
    "n_switch = round((t_end - t_start) / dt_switch)   # number of switching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import os, glob\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# if the result.csv file exists, take data and calculate Âµ_t\n",
    "growth_df = pd.DataFrame()\n",
    "growth_t_df = pd.DataFrame()\n",
    "growth_t_df_MA = pd.DataFrame()\n",
    "data_list_t = []\n",
    "pop_area_df = pd.DataFrame()\n",
    "cell_area_mean_df = pd.DataFrame()\n",
    "cell_area_std_df = pd.DataFrame()\n",
    "cell_number_df = pd.DataFrame()\n",
    "\n",
    "for sub_folder in latest_folder.glob(\"execution*\"):\n",
    "    data_list = []\n",
    "    data_folder =  sub_folder / \"tmp\"\n",
    "    data_files = os.listdir(data_folder)\n",
    "    \n",
    "    if \"result.csv\" not in data_files:\n",
    "        print(sub_folder.name, 'was not analyzed')\n",
    "        \n",
    "    else:\n",
    "        sub_df = pd.read_csv(data_folder / \"result.csv\", delimiter = ';')\n",
    "        \n",
    "        # data smoothing by centered moving average (MA) for Âµ_t calculation\n",
    "        sub_df['moving_average'] = sub_df['area_sum'].rolling(window=5, center=True).mean()\n",
    "        sub_df['moving_average_single'] = sub_df['area_mean'].rolling(window=5, center=True).mean()\n",
    "        \n",
    "        # calculate Âµ_t (transient Âµ, first derivative of growth curve)\n",
    "        Âµt_df = sub_df[(sub_df['time'] >= t_start) & (sub_df['time'] <= t_end)]\n",
    "        y_area = np.log(Âµt_df['area_sum'])\n",
    "        dy_area = np.gradient(y_area, dt_image)\n",
    "        dy_area_series = pd.Series(dy_area)\n",
    "        growth_t_df[sub_folder.name] = dy_area_series\n",
    "        \n",
    "        # calculate Âµ_t from moving-averaged area sum\n",
    "        y_area_MA = np.log(Âµt_df['moving_average'])\n",
    "        dy_area_MA = np.gradient(y_area_MA, dt_image)\n",
    "        dy_area_series_MA = pd.Series(dy_area_MA)\n",
    "        growth_t_df_MA[sub_folder.name] = dy_area_series_MA\n",
    "        \n",
    "        # calculate Âµ_step (Âµ for each switching step)\n",
    "        for i in range(n_switch):\n",
    "            min_time_i = t_start + i * dt_switch\n",
    "            max_time_i = min_time_i + dt_switch\n",
    "            timed_df_i = sub_df[(sub_df['time'] > min_time_i) & (sub_df['time'] < max_time_i)]\n",
    "            m, b = np.polyfit(timed_df_i['time'], np.log(timed_df_i['area_sum']), 1)\n",
    "            data_list.append({sub_folder.name : m})\n",
    "            \n",
    "        data_list_df = pd.DataFrame(data_list)\n",
    "        growth_df = pd.concat([growth_df, data_list_df], axis=1)\n",
    "        \n",
    "        # collect 'area_sum' & 'area_mean' & 'area_std' from all the analyzed chambers\n",
    "        pop_area_df[sub_folder.name] = sub_df['area_sum']\n",
    "        cell_area_mean_df[sub_folder.name] = sub_df['area_mean'] \n",
    "        cell_area_std_df[sub_folder.name] = sub_df['area_std']\n",
    "        cell_number_df[sub_folder.name] = sub_df['counts']\n",
    "\n",
    "        \n",
    "# save summary of population area, then save\n",
    "pop_area_df.insert(0, 'time', sub_df['time'])\n",
    "pop_area_df['mean'] = pop_area_df.mean(axis=1)\n",
    "pop_area_df['std'] = pop_area_df.std(axis=1)\n",
    "pop_area_df.to_csv('./ population-area_summary.csv', decimal='.', sep=';')\n",
    "\n",
    "# calculate mean & std of Âµ_t, then save\n",
    "growth_t_df['mean'] = growth_t_df.mean(axis=1)\n",
    "growth_t_df['std'] = growth_t_df.std(axis=1)\n",
    "time_series = np.arange(t_start, t_end + dt_image, dt_image)\n",
    "growth_t_df.insert(0, 'time', time_series)\n",
    "growth_t_df.to_csv('./ derivative-growth-rate_summary.csv', decimal='.', sep=';')\n",
    "\n",
    "# calculate mean & std of Âµ_t (moving averaged), then save\n",
    "growth_t_df_MA['mean'] = growth_t_df_MA.mean(axis=1)\n",
    "growth_t_df_MA['std'] = growth_t_df_MA.std(axis=1)\n",
    "growth_t_df_MA.insert(0, 'time', time_series)\n",
    "growth_t_df_MA.to_csv('./ derivative-growth-rate_MA_summary.csv', decimal='.', sep=';')\n",
    "\n",
    "# calculate mean & std of all aerobic & anaerobic growth\n",
    "aerobic_rows = growth_df.iloc[0::2]   # even rows\n",
    "anaerobic_rows = growth_df.iloc[1::2]   # odd rows\n",
    "\n",
    "mean_aerobic = aerobic_rows.values.flatten().mean()\n",
    "std_aerobic = aerobic_rows.values.flatten().std()\n",
    "mean_anaerobic = anaerobic_rows.values.flatten().mean()\n",
    "std_anaerobic = anaerobic_rows.values.flatten().std()\n",
    "\n",
    "# save growth values\n",
    "array = np.array([[mean_aerobic, std_aerobic], [mean_anaerobic, std_anaerobic]])\n",
    "index_values = ['aerobic', 'anaerobic']\n",
    "column_values = ['mean', 'std']\n",
    "all_growth_df = pd.DataFrame(data = array,\n",
    "                              index = index_values,\n",
    "                              columns = column_values)\n",
    "\n",
    "print(all_growth_df)\n",
    "all_growth_df.to_csv('./ step-growth-rate_mean-std.csv', decimal='.', sep=';')\n",
    "\n",
    "# calculate mean & std of aerobic & anaerobic growth for each step\n",
    "growth_df['mean'] = growth_df.mean(axis=1)\n",
    "growth_df['std'] = growth_df.std(axis=1)\n",
    "growth_df.to_csv('./ step-growth-rate_summary.csv', decimal='.', sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantaneous growth rate summary in a plot\n",
    "\n",
    "import matplotlib.ticker as ticker\n",
    "\n",
    "# Set values for plotting\n",
    "x = growth_t_df_MA['time']\n",
    "y = growth_t_df_MA['mean']\n",
    "yerr = growth_t_df_MA['std']\n",
    "\n",
    "# Make plot\n",
    "fig, axs = plt.subplots(figsize=(10, 5))\n",
    "tick_spacing = dt_switch\n",
    "\n",
    "fig.suptitle('Âµ_t')\n",
    "axs.plot(x, y, color='gray', label='mean')\n",
    "axs.fill_between(x, y - yerr, y + yerr, alpha=0.2, color='gray', label='Std.')\n",
    "axs.set_xlabel('Time [h]')\n",
    "axs.set_ylabel('Âµ_t [1/h]')\n",
    "axs.xaxis.set_major_locator(ticker.MultipleLocator(tick_spacing))\n",
    "axs.grid(axis = 'x')\n",
    "axs.legend(loc='upper right')\n",
    "plt.savefig('./ instantaneous-growth-rate.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Segment data into periods for polar plot\n",
    "\n",
    "df_original = pd.read_csv('_derivative-growth-rate_MA_summary.csv')\n",
    "\n",
    "dt_switch_min = 30   # switching duration in minute (half period)\n",
    "t_polar = 6 * 2 * dt_switch_min   # number of row in a period (imaging every 10 seconds)\n",
    "t_half = 6* dt_switch_min   # number of row in half a period (imaging every 10 seconds)\n",
    "\n",
    "df_polar = pd.DataFrame()\n",
    "df_aerobic = pd.DataFrame()\n",
    "df_anaerobic = pd.DataFrame()\n",
    "\n",
    "# Segment the DataFrame into chunks and assign to new columns\n",
    "for i in range(0, len(df_original)-t_polar, t_polar):\n",
    "    \n",
    "    # Slice the DataFrame: rows from i to i+t_polar\n",
    "    segment = df_original['mean'].iloc[i:i+t_polar+1].reset_index(drop=True)\n",
    "    \n",
    "    # Add the segment as a new column in the new DataFrame\n",
    "    df_polar[f'period_{i//t_polar}'] = segment\n",
    "\n",
    "df_polar['mean'] = df_polar.mean(axis=1)\n",
    "df_polar['std'] = df_polar.std(axis=1)\n",
    "\n",
    "df_polar.to_csv('./ derivative-growth-rate_MA_polar.csv', decimal='.', sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "vscode": {
   "interpreter": {
    "hash": "43e720662e2b73f3f858656968524fca68eb44fc0b1d15b9eb878c7d185562f9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
